{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "# something about warnings\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #Limiting floats output to 3 decimal points\n",
    "#pd.options.mode.chained_assignment = None\n",
    "\n",
    "#Machine learning libraries\n",
    "#import keras (This is only commented out because Aviv couldn't install keras on his conda.  He will fix this eventually)\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# changes display options to allow many rows and columns to be displayed\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999\n",
    "# uploads data sets\n",
    "train = pd.read_csv(\"../Data/House Prices Advanced Regression Techniques/train.csv\")\n",
    "test = pd.read_csv(\"../Data/House Prices Advanced Regression Techniques/test.csv\")\n",
    "train=train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n",
    "total = pd.concat([train, test], axis=0)\n",
    "total2 =total.copy()\n",
    "# changes display options to allow many rows and columns to be displayed\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start encoding BldgType\n",
      "Start encoding BsmtExposure\n",
      "Start encoding CentralAir\n",
      "Start encoding Condition1\n",
      "Start encoding Condition2\n",
      "Start encoding Electrical\n",
      "Start encoding Exterior1st\n",
      "Start encoding Exterior2nd\n",
      "Start encoding Fence\n",
      "Start encoding Foundation\n",
      "Start encoding GarageType\n",
      "Start encoding Heating\n",
      "Start encoding HouseStyle\n",
      "Start encoding LandContour\n",
      "Start encoding LotConfig\n",
      "Start encoding MSSubClass\n",
      "Start encoding MSZoning\n",
      "Start encoding MasVnrType\n",
      "Start encoding MiscFeature\n",
      "Start encoding MoSold\n",
      "Start encoding Neighborhood\n",
      "Start encoding RoofMatl\n",
      "Start encoding RoofStyle\n",
      "Start encoding SaleCondition\n",
      "Start encoding SaleType\n",
      "Start encoding YrSold\n"
     ]
    }
   ],
   "source": [
    "# makes an indicator variable for whether there was LotFrontage was NA\n",
    "cond = total2['LotFrontage'].isnull()\n",
    "total2['HasLotFrontage'] = cond * 1\n",
    "\n",
    "# gets LotFrontage from sqrt(LotArea) for a new LotFrontage variable\n",
    "total2['LotFrontage2'] = total2['LotFrontage']\n",
    "sqrtlotarea = np.sqrt(total2['LotArea'])\n",
    "total2['LotFrontage2'][cond] = sqrtlotarea[cond]\n",
    "\n",
    "# changes NaN's in GarageType to \"None\" and imputes yearbuilt for garageyrblt for houses with no garages\n",
    "cond = total2['GarageType'].isnull()\n",
    "total2['GarageType'][cond] = \"None\"\n",
    "total2['GarageYrBlt'][cond] = total2['YearBuilt'][cond]\n",
    "\n",
    "# imputes -1 for missing values in MasVnrArea\n",
    "total2.MasVnrArea = total2.MasVnrArea.fillna(-1)\n",
    "\n",
    "# removes changes null values that shouldn't be treated as null\n",
    "total2['Alley'] = total2['Alley'].fillna(\"None\")\n",
    "total2['BsmtQual'] = total2['BsmtQual'].fillna(\"None\")\n",
    "total2['BsmtCond'] = total2['BsmtCond'].fillna(\"None\")\n",
    "total2['BsmtExposure'] = total2['BsmtExposure'].fillna(\"None\")\n",
    "total2['BsmtFinType1'] = total2['BsmtFinType1'].fillna(\"None\")\n",
    "total2['BsmtFinType2'] = total2['BsmtFinType2'].fillna(\"None\")\n",
    "total2['FireplaceQu'] = total2['FireplaceQu'].fillna(\"None\")\n",
    "total2['GarageType'] = total2['GarageType'].fillna(\"None\")\n",
    "total2['GarageFinish'] = total2['GarageFinish'].fillna(\"None\")\n",
    "total2['GarageQual'] = total2['GarageQual'].fillna(\"None\")\n",
    "total2['GarageCond'] = total2['GarageCond'].fillna(\"None\")\n",
    "total2['PoolQC'] = total2['PoolQC'].fillna(\"None\")\n",
    "total2['Fence'] = total2['Fence'].fillna(\"None\")\n",
    "total2['MiscFeature'] = total2['MiscFeature'].fillna(\"None\")\n",
    "total2['MasVnrType'] = total2['MasVnrType'].fillna(\"missing\")\n",
    "\n",
    "# recodes some categorical variables as ordinal\n",
    "total2 = total2.replace({\"Alley\" : {\"None\" : 0, \"Grvl\" : 1, \"Pave\" : 2},\n",
    "                       \"BsmtCond\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"BsmtExposure\" : {\"None\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n",
    "                       \"BsmtFinType1\" : {\"None\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtFinType2\" : {\"None\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtQual\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"FireplaceQu\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \n",
    "                                       \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n",
    "                       \"GarageCond\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"GarageFinish\" : {\"None\" : 0, \"Unf\" : 1, \"RFn\" : 2, \"Fin\" : 3},\n",
    "                       \"GarageQual\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3},\n",
    "                       \"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4},\n",
    "                       \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n",
    "                       \"PoolQC\" : {\"None\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                       \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2},\n",
    "                       \"Utilities\" : {\"ELO\" : 1, \"NoSeWa\" : 2, \"NoSewr\" : 3, \"AllPub\" : 4}})\n",
    "\n",
    "# fixing specific na cells\n",
    "total2.BsmtFinSF1 = total2.BsmtFinSF1.fillna(0)\n",
    "total2.BsmtFinSF2 = total2.BsmtFinSF2.fillna(0)\n",
    "total2.BsmtFullBath = total2.BsmtFullBath.fillna(0)\n",
    "total2.BsmtHalfBath = total2.BsmtHalfBath.fillna(0)\n",
    "total2.BsmtUnfSF = total2.BsmtUnfSF.fillna(0)\n",
    "\n",
    "\n",
    "total2 = total2.fillna(total2.mean())\n",
    "total2 = total2.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "total2.SalePrice = np.log(total2.SalePrice) ##log transform for the response var\n",
    "total2['MSSubClass']=total2['MSSubClass'].apply(str)\n",
    "total2['YrSold'] = total2['YrSold'].astype(str)\n",
    "total2['MoSold'] = total2['MoSold'].astype(str)\n",
    "total2['TotalSF'] = total2['TotalBsmtSF'] + total2['1stFlrSF'] + total2['2ndFlrSF']\n",
    "\n",
    "intFeature = total2.select_dtypes(include=[\"int64\"]).apply(lambda x: skew(x.astype(float).dropna()))\n",
    "skewIntFeat = intFeature[intFeature > .75].index.tolist()\n",
    "total2[skewIntFeat] = total2[skewIntFeat].apply(np.log1p)\n",
    "total2.drop(\"Id\", axis=1, inplace=True)\n",
    "total2.drop(\"LotFrontage\",axis=1,inplace=True)\n",
    "#total2.drop(\"HasLotFrontage\",axis=1,inplace=True)\n",
    "\n",
    "catCol = total2.select_dtypes([\"object\"]).columns.tolist()\n",
    "LabelMap = dict()\n",
    "for i in catCol:\n",
    "    print('Start encoding ' + i)\n",
    "    total2[i] = total2[i].fillna('missing')\n",
    "    le = LabelEncoder()\n",
    "    le.fit(total2[i].astype(str))\n",
    "    LabelMap[i] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "#total2.replace(LabelMap, inplace=True)\n",
    "total2 = pd.get_dummies(total2)\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2917, 263)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = total2[:train.shape[0]]\n",
    "X_train = dtrain.drop(\"SalePrice\", axis=1)\n",
    "y_train = dtrain['SalePrice']\n",
    "dtest = total2[train.shape[0]:]\n",
    "X_test = dtest.drop(\"SalePrice\", axis=1)\n",
    "y_test = dtest['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0729484397415\n"
     ]
    }
   ],
   "source": [
    "## LightGBM\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "model_lgb.fit(X_train, y_train)\n",
    "lgb_train_pred = model_lgb.predict(X_train)\n",
    "lgb_pred = np.expm1(model_lgb.predict(X_test))\n",
    "print(rmsle(y_train, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0795760656427\n"
     ]
    }
   ],
   "source": [
    "## XGBoost\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "xgb_train_pred = model_xgb.predict(X_train)\n",
    "xgb_pred = np.expm1(model_xgb.predict(X_test))\n",
    "print(rmsle(y_train, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True).get_n_splits(X_train)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005))\n",
    "#Lasso = Lasso(alpha=0.0005,max_iter=10000)\n",
    "#ridge = Ridge(alpha=60)\n",
    "Lasso = make_pipeline(RobustScaler(), Lasso(alpha = np.exp(-8), normalize=False ))\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9))\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "#SVRr = SVR(C= 13, epsilon= 0.009, gamma= 0.0004,kernel='rbf' )\n",
    "SVRr = SVR(C = 0.2, epsilon = 0.1, kernel = 'linear' )\n",
    "BR = BayesianRidge()\n",
    "NN = make_pipeline(\n",
    "    RobustScaler(),\n",
    "    MLPRegressor(\n",
    "                hidden_layer_sizes = (200, 20),\n",
    "                activation = \"logistic\",\n",
    "                solver = 'lbfgs',\n",
    "                alpha = 0.001,\n",
    "                random_state = 0\n",
    "                )\n",
    ")\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stacking\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)\n",
    "\n",
    "\n",
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR,SVRr,BR,NN),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "#print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stacked_averaged_models.fit(np.array(X_train), np.array(y_train))\n",
    "stacked_train_pred = stacked_averaged_models.predict(X_train)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(X_test))\n",
    "print(rmsle(y_train, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcsv = pd.DataFrame({'Id': test['Id'], 'SalePrice': ensemble})\n",
    "subcsv.to_csv(\"prediction1nopc.csv\", index=False)\n",
    "subcsv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
